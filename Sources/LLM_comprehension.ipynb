{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables.\n",
    "load_dotenv()\n",
    "\n",
    "# Set the model name for our LLMs.\n",
    "OPENAI_MODEL = \"gpt-3.5-turbo\"\n",
    "# Store the API key in a variable.\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Templating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports for the chain and templates.\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import PromptTemplate, FewShotPromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model.\n",
    "llm=ChatOpenAI(openai_api_key=OPENAI_API_KEY, model_name=OPENAI_MODEL, temperature=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1 - \"Mary Poppins\"\n",
    "warm_prefix = \"\"\"\n",
    "Here are examples between a human and AI. The human provides whether \n",
    "the human walked today or not,possibly with amount of distance walked if the human did walk, \n",
    "and the AI provides a single sentence that encourages and praises if the human walked, or\n",
    "try to give motivational sentence if the human did not walk. If the human did not walk more than \n",
    "at least a mile, the AI would encourage to walk more next time. The responses should be nice,\n",
    "warm, and soothing. For example:\n",
    "\"\"\"\n",
    "warm_examples = [{\n",
    "    'query' : 'Yes I walked today',\n",
    "    'answer' : 'Great job! Keep up.'\n",
    "},{\n",
    "    'query' : 'Yep, I walked 2 whole miles!',\n",
    "    'answer' : 'Wow, great work! I am proud of you!'\n",
    "},{\n",
    "    'query' : 'No, I did not have time to walk today.',\n",
    "    'answer' : 'Oh no, I hope you have time to walk tomorrow!'\n",
    "},{\n",
    "    'query' : 'No, it was raining hard outside.',\n",
    "    'answer' : 'That is unfortunate! I hope tomorrow is sunny so you can go out for a nice walk!'\n",
    "},{\n",
    "    'query' : 'Yes I walked 200 ft today.',\n",
    "    'answer' : 'Well at least you walked today! It would be better if you have walked more than that though!'\n",
    "}]\n",
    "\n",
    "response_format = \"\"\"\n",
    "Human: {query}\n",
    "AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "example_warm = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\"],\n",
    "    template=response_format\n",
    ")\n",
    "\n",
    "suffix = \"\"\"\n",
    "Human: {query}\n",
    "AI: \n",
    "\"\"\"\n",
    "\n",
    "warm_template = FewShotPromptTemplate(\n",
    "    examples=warm_examples,\n",
    "    example_prompt=example_warm,\n",
    "    input_variables=[\"query\"],\n",
    "    prefix=warm_prefix,\n",
    "    suffix=suffix,\n",
    "    example_separator=\"\\n\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every step counts! Keep up the good work and try to push yourself a little further next time. You got this!\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=warm_template)\n",
    "query = input(\"Did you walk today?\")\n",
    "result = chain.run(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2 - \"Someone mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3 - \"Somewhere in between\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
